# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨æ•°æ®é¢„ç¼“å­˜è°ƒåº¦å™¨
ç”¨äºå®šæ—¶é¢„ç¼“å­˜ä¸Šè¯æŒ‡æ•°æˆåˆ†è‚¡æ•°æ®ï¼Œæå‡å¸‚åœºæ‰«ææ€§èƒ½
"""

import time
import threading
import logging
from datetime import datetime, timedelta
import traceback
import os

# å°è¯•å¯¼å…¥å¯é€‰ä¾èµ–
try:
    import akshare as ak
    AKSHARE_AVAILABLE = True
except ImportError:
    AKSHARE_AVAILABLE = False
    ak = None

try:
    from data_service import data_service
    DATA_SERVICE_AVAILABLE = True
except ImportError:
    DATA_SERVICE_AVAILABLE = False
    data_service = None

try:
    from database import get_session, StockBasicInfo, StockPriceHistory
    DATABASE_AVAILABLE = True
except ImportError:
    DATABASE_AVAILABLE = False

# Hugging Face Spaces å…¼å®¹æ€§æ£€æŸ¥
HF_SPACES_MODE = os.getenv('SPACE_ID') is not None

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('precache_scheduler.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class StockPrecacheScheduler:
    """è‚¡ç¥¨æ•°æ®é¢„ç¼“å­˜è°ƒåº¦å™¨"""

    def __init__(self):
        self.is_running = False
        self.scheduler_thread = None
        self.precache_stats = {
            'last_run': None,
            'total_stocks': 0,
            'success_count': 0,
            'failed_count': 0,
            'duration': 0
        }
        self.scheduled_time = "00:00"  # é»˜è®¤å‡Œæ™¨12ç‚¹æ‰§è¡Œ
    
    def get_index_stocks(self, index_code='000300'):
        """è·å–æŒ‡æ•°æˆåˆ†è‚¡åˆ—è¡¨"""
        try:
            logger.info(f"å¼€å§‹è·å–æŒ‡æ•° {index_code} æˆåˆ†è‚¡åˆ—è¡¨")

            if AKSHARE_AVAILABLE and ak:
                if index_code == '000300':  # æ²ªæ·±300
                    df = ak.index_stock_cons(symbol="000300")
                    stock_codes = df['å“ç§ä»£ç '].tolist()
                elif index_code == '000001':  # ä¸Šè¯æŒ‡æ•°
                    df = ak.index_stock_cons(symbol="000001")
                    stock_codes = df['å“ç§ä»£ç '].tolist()
                elif index_code == '399001':  # æ·±è¯æˆæŒ‡
                    df = ak.index_stock_cons(symbol="399001")
                    stock_codes = df['å“ç§ä»£ç '].tolist()
                else:
                    # é»˜è®¤ä½¿ç”¨æ²ªæ·±300å‰50åªè‚¡ç¥¨
                    df = ak.index_stock_cons(symbol="000300")
                    stock_codes = df['å“ç§ä»£ç '].head(50).tolist()

                logger.info(f"æˆåŠŸè·å– {len(stock_codes)} åªæˆåˆ†è‚¡")
                return stock_codes
            else:
                logger.warning("AKShareä¸å¯ç”¨ï¼Œä½¿ç”¨é¢„å®šä¹‰è‚¡ç¥¨åˆ—è¡¨")
                raise Exception("AKShareä¸å¯ç”¨")

        except Exception as e:
            logger.error(f"è·å–æŒ‡æ•°æˆåˆ†è‚¡å¤±è´¥: {e}")
            # è¿”å›ä¸€äº›å¸¸è§çš„å¤§ç›˜è‚¡ä½œä¸ºå¤‡é€‰
            return [
                '000001', '000002', '600000', '600036', '000858',
                '002415', '000063', '600519', '000166', '600276',
                '600887', '000725', '002304', '600031', '000568',
                '600104', '002142', '600009', '000776', '600028'
            ]
    
    def precache_stock_data(self, stock_code, market_type='A'):
        """é¢„ç¼“å­˜å•åªè‚¡ç¥¨çš„æ•°æ®"""
        try:
            logger.debug(f"å¼€å§‹é¢„ç¼“å­˜è‚¡ç¥¨ {stock_code} æ•°æ®")

            if not DATA_SERVICE_AVAILABLE or not data_service:
                logger.warning("æ•°æ®æœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡é¢„ç¼“å­˜")
                return False

            # 1. é¢„ç¼“å­˜åŸºæœ¬ä¿¡æ¯
            basic_info = data_service.get_stock_basic_info(stock_code, market_type)
            if basic_info:
                logger.debug(f"è‚¡ç¥¨ {stock_code} åŸºæœ¬ä¿¡æ¯ç¼“å­˜æˆåŠŸ")

            # 2. é¢„ç¼“å­˜å†å²ä»·æ ¼æ•°æ®ï¼ˆæœ€è¿‘1å¹´ï¼‰
            end_date = datetime.now().strftime('%Y-%m-%d')
            start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')

            price_data = data_service.get_stock_price_history(
                stock_code, market_type, start_date, end_date
            )
            if price_data is not None and len(price_data) > 0:
                logger.debug(f"è‚¡ç¥¨ {stock_code} ä»·æ ¼å†å²æ•°æ®ç¼“å­˜æˆåŠŸï¼Œå…± {len(price_data)} æ¡è®°å½•")

            # 3. é¢„ç¼“å­˜å®æ—¶æ•°æ®
            realtime_data = data_service.get_stock_realtime_data(stock_code, market_type)
            if realtime_data:
                logger.debug(f"è‚¡ç¥¨ {stock_code} å®æ—¶æ•°æ®ç¼“å­˜æˆåŠŸ")

            return True

        except Exception as e:
            logger.error(f"é¢„ç¼“å­˜è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {e}")
            return False
    
    def run_precache_task(self, index_code='000300', max_stocks=100):
        """æ‰§è¡Œé¢„ç¼“å­˜ä»»åŠ¡"""
        start_time = time.time()
        logger.info("="*60)
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œè‚¡ç¥¨æ•°æ®é¢„ç¼“å­˜ä»»åŠ¡")
        logger.info("="*60)
        
        try:
            # è·å–æŒ‡æ•°æˆåˆ†è‚¡
            stock_codes = self.get_index_stocks(index_code)
            
            # é™åˆ¶è‚¡ç¥¨æ•°é‡
            if len(stock_codes) > max_stocks:
                stock_codes = stock_codes[:max_stocks]
                logger.info(f"é™åˆ¶é¢„ç¼“å­˜è‚¡ç¥¨æ•°é‡ä¸º {max_stocks} åª")
            
            total_stocks = len(stock_codes)
            success_count = 0
            failed_count = 0
            
            logger.info(f"å¼€å§‹é¢„ç¼“å­˜ {total_stocks} åªè‚¡ç¥¨çš„æ•°æ®")
            
            # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…è¿‡åº¦å ç”¨èµ„æº
            batch_size = 10
            for i in range(0, total_stocks, batch_size):
                batch = stock_codes[i:i + batch_size]
                logger.info(f"å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(total_stocks + batch_size - 1)//batch_size}")
                
                for stock_code in batch:
                    try:
                        if self.precache_stock_data(stock_code):
                            success_count += 1
                            logger.info(f"âœ… {stock_code} é¢„ç¼“å­˜æˆåŠŸ ({success_count}/{total_stocks})")
                        else:
                            failed_count += 1
                            logger.warning(f"âŒ {stock_code} é¢„ç¼“å­˜å¤±è´¥ ({failed_count}/{total_stocks})")
                    except Exception as e:
                        failed_count += 1
                        logger.error(f"âŒ {stock_code} é¢„ç¼“å­˜å¼‚å¸¸: {e}")
                
                # æ‰¹æ¬¡é—´ä¼‘æ¯ï¼Œé¿å…APIé™æµ
                if i + batch_size < total_stocks:
                    time.sleep(2)
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            duration = time.time() - start_time
            self.precache_stats.update({
                'last_run': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_stocks': total_stocks,
                'success_count': success_count,
                'failed_count': failed_count,
                'duration': duration
            })
            
            logger.info("="*60)
            logger.info("ğŸ“Š é¢„ç¼“å­˜ä»»åŠ¡å®Œæˆç»Ÿè®¡")
            logger.info("="*60)
            logger.info(f"æ€»è‚¡ç¥¨æ•°: {total_stocks}")
            logger.info(f"æˆåŠŸç¼“å­˜: {success_count}")
            logger.info(f"å¤±è´¥æ•°é‡: {failed_count}")
            logger.info(f"æˆåŠŸç‡: {(success_count/total_stocks*100):.1f}%")
            logger.info(f"æ€»è€—æ—¶: {duration:.1f}ç§’")
            logger.info(f"å¹³å‡æ¯åª: {duration/total_stocks:.2f}ç§’")
            
        except Exception as e:
            logger.error(f"é¢„ç¼“å­˜ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            logger.error(traceback.format_exc())
    
    def schedule_daily_precache(self, time_str="00:00", index_code='000300'):
        """å®‰æ’æ¯æ—¥é¢„ç¼“å­˜ä»»åŠ¡"""
        logger.info(f"å®‰æ’æ¯æ—¥ {time_str} æ‰§è¡Œé¢„ç¼“å­˜ä»»åŠ¡")

        self.scheduled_time = time_str
        self.index_code = index_code

        logger.info(f"é¢„ç¼“å­˜ä»»åŠ¡å·²å®‰æ’åœ¨æ¯å¤© {time_str} æ‰§è¡Œ")
    
    def start_scheduler(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        if self.is_running:
            logger.warning("è°ƒåº¦å™¨å·²åœ¨è¿è¡Œä¸­")
            return

        self.is_running = True

        def run_scheduler():
            logger.info("é¢„ç¼“å­˜è°ƒåº¦å™¨å¯åŠ¨")
            while self.is_running:
                try:
                    # æ£€æŸ¥æ˜¯å¦åˆ°äº†æ‰§è¡Œæ—¶é—´
                    current_time = datetime.now().strftime("%H:%M")
                    if current_time == self.scheduled_time:
                        logger.info("åˆ°è¾¾é¢„å®šæ—¶é—´ï¼Œå¼€å§‹æ‰§è¡Œé¢„ç¼“å­˜ä»»åŠ¡")
                        self.run_precache_task(getattr(self, 'index_code', '000300'))
                        # ç­‰å¾…ä¸€åˆ†é’Ÿï¼Œé¿å…é‡å¤æ‰§è¡Œ
                        time.sleep(60)

                    time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                except Exception as e:
                    logger.error(f"è°ƒåº¦å™¨è¿è¡Œå¼‚å¸¸: {e}")
                    time.sleep(60)
            logger.info("é¢„ç¼“å­˜è°ƒåº¦å™¨åœæ­¢")

        self.scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
        self.scheduler_thread.start()
        logger.info("é¢„ç¼“å­˜è°ƒåº¦å™¨å·²å¯åŠ¨")
    
    def stop_scheduler(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        if not self.is_running:
            logger.warning("è°ƒåº¦å™¨æœªåœ¨è¿è¡Œ")
            return
        
        self.is_running = False
        if self.scheduler_thread:
            self.scheduler_thread.join(timeout=5)
        logger.info("é¢„ç¼“å­˜è°ƒåº¦å™¨å·²åœæ­¢")
    
    def get_stats(self):
        """è·å–é¢„ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        return self.precache_stats.copy()
    
    def manual_precache(self, index_code='000300', max_stocks=50):
        """æ‰‹åŠ¨æ‰§è¡Œé¢„ç¼“å­˜ä»»åŠ¡"""
        logger.info("æ‰‹åŠ¨æ‰§è¡Œé¢„ç¼“å­˜ä»»åŠ¡")
        self.run_precache_task(index_code, max_stocks)

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
precache_scheduler = StockPrecacheScheduler()

def init_precache_scheduler():
    """åˆå§‹åŒ–é¢„ç¼“å­˜è°ƒåº¦å™¨"""
    try:
        # åœ¨Hugging Face Spacesç¯å¢ƒä¸­ï¼Œå¯èƒ½ä¸éœ€è¦å¯åŠ¨è°ƒåº¦å™¨
        if HF_SPACES_MODE:
            logger.info("æ£€æµ‹åˆ°Hugging Face Spacesç¯å¢ƒï¼Œè·³è¿‡è‡ªåŠ¨è°ƒåº¦å™¨å¯åŠ¨")
            return True
        
        # å®‰æ’æ¯å¤©å‡Œæ™¨12ç‚¹æ‰§è¡Œé¢„ç¼“å­˜
        precache_scheduler.schedule_daily_precache("00:00", "000300")
        
        # å¯åŠ¨è°ƒåº¦å™¨
        precache_scheduler.start_scheduler()
        
        logger.info("è‚¡ç¥¨æ•°æ®é¢„ç¼“å­˜è°ƒåº¦å™¨åˆå§‹åŒ–å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"é¢„ç¼“å­˜è°ƒåº¦å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    # æµ‹è¯•é¢„ç¼“å­˜åŠŸèƒ½
    scheduler = StockPrecacheScheduler()
    
    # æ‰‹åŠ¨æ‰§è¡Œä¸€æ¬¡é¢„ç¼“å­˜ï¼ˆæµ‹è¯•ç”¨ï¼Œåªç¼“å­˜10åªè‚¡ç¥¨ï¼‰
    scheduler.manual_precache("000300", 10)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    stats = scheduler.get_stats()
    print("\né¢„ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
